{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "import glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_data = True\n",
    "image_path = './img/data/*.jpg'\n",
    "addrs = glob.glob(image_path)\n",
    "addrs = np.string_(addrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if shuffle_data:\n",
    "   # c = list(zip(addrs, labels))\n",
    "    shuffle(addrs)\n",
    "    #addrs, labels = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_addrs = addrs[int(0.9*len(addrs)):]\n",
    "\n",
    "dev_addrs = addrs[int(0.8*len(addrs)):int(0.9*len(addrs))]\n",
    "\n",
    "train_addrs = addrs[0:int(0.8*len(addrs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# address to where you want to save the hdf5 file\n",
    "train_path = \"./Output/v2/train/\"\n",
    "test_path = \"./Output/v2/test/\"\n",
    "dev_path = \"./Output/v2/dev/\"\n",
    "hdf5_path = './Output/v2/hdf5/blooddata-color.hdf5'\n",
    "img_width = 100\n",
    "img_height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_2_destination(dataset, destDir):\n",
    "    for i in range(len(dataset)):\n",
    "        im = dataset[i]\n",
    "        fileName = (os.path.basename(im)).decode('UTF-8')\n",
    "        #trunk the file name by removing rotations.\n",
    "        pos = fileName.find('tif') + 3\n",
    "        fileName = fileName[: pos]\n",
    "        fileName = destDir + fileName\n",
    "        img = cv2.imread(im.decode('utf-8')) #load image\n",
    "        cv2.imwrite(fileName,img) #write image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images_2_destination(dev_addrs, dev_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images_2_destination(test_addrs, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images_2_destination(train_addrs, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shape = (len(train_addrs), img_height, img_width, 3)\n",
    "test_shape = (len(test_addrs), img_height, img_width, 3)\n",
    "dev_shape = (len(dev_addrs), img_height, img_width, 3) # New\n",
    "\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "hdf5_file.create_dataset(\"train_imgs_resized\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_imgs_resized\", test_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"dev_imgs_resized\", dev_shape, np.int8) #new\n",
    "\n",
    "#hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "\n",
    "hdf5_file.create_dataset(\"train_addrs\", (len(train_addrs),), dtype=\"S20\")\n",
    "hdf5_file[\"train_addrs\"][...] = train_addrs\n",
    "hdf5_file.create_dataset(\"test_addrs\", (len(test_addrs),), dtype=\"S20\")\n",
    "hdf5_file[\"test_addrs\"][...] = test_addrs \n",
    "hdf5_file.create_dataset(\"dev_addrs\", (len(dev_addrs),), dtype=\"S20\")\n",
    "hdf5_file[\"dev_addrs\"][...] = dev_addrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a numpy array to save the mean of the images\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "   \n",
    "    # read an image \n",
    "    addr = train_addrs[i]\n",
    "    #print(str(addr))\n",
    "    \n",
    "    # cv2 load images\n",
    "    img = cv2.imread(addr.decode('utf-8'))\n",
    "    \n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_file[\"train_imgs_resized\"][i, ...] = img[None]\n",
    "    #mean += img / float(len(train_labels))\n",
    "\n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "   \n",
    "    # read an image \n",
    "    # cv2 load images\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr.decode('utf-8'))\n",
    "    \n",
    "    # save the image\n",
    "    hdf5_file[\"test_imgs_resized\"][i, ...] = img[None]\n",
    "\n",
    "# loop over dev addresses\n",
    "for i in range(len(dev_addrs)):\n",
    "   \n",
    "    # read an image \n",
    "    # cv2 load images\n",
    "    addr = dev_addrs[i]\n",
    "    img = cv2.imread(addr.decode('utf-8'))\n",
    "    \n",
    "    # save the image\n",
    "    hdf5_file[\"dev_imgs_resized\"][i, ...] = img[None]\n",
    "# save the mean and close the hdf5 file\n",
    "#hdf5_file[\"train_mean\"][...] = mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "082bd1cb04d28c61bf8f444dd2514aaa1445b5335bf61d7f3e0a9ed0d28b3c4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
