{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import shuffle\n",
    "from random import shuffle\n",
    "import glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdf5_path = 'C:/Users/ateya/OneDrive/Desktop/Graduate Research/RecentUpdate/bloodataset/blooddata1.hdf5'  # address to where you want to save the hdf5 file\n",
    "hdf5_path = './blooddata-color.hdf5'\n",
    "img_width = 100\n",
    "img_height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_data = True  # shuffle the addresses before saving\n",
    "#train_path = './train_images_rotated/*.jpg'\n",
    "\n",
    "#test_path = './test_images_rotated/*.jpg'\n",
    "image_path = './images/*.jpg'\n",
    "# read addresses and labels from the 'train' folder\n",
    "addrs = glob.glob(image_path)\n",
    "#testAddrs = glob.glob(test_path)\n",
    "\n",
    "def createLabels(addrs):\n",
    "    labels = []\n",
    "    for addr in addrs:\n",
    "        if '10_' in addr:\n",
    "            labels.append(10)\n",
    "        elif '20_' in addr:\n",
    "            labels.append(20)\n",
    "        elif '30_' in addr:\n",
    "            labels.append(30)\n",
    "        elif '40_' in addr:\n",
    "            labels.append(40)\n",
    "        elif '50_' in addr:\n",
    "            labels.append(50)\n",
    "        elif '60_' in addr:\n",
    "            labels.append(60)\n",
    "        elif '70_' in addr:\n",
    "            labels.append(70)\n",
    "        elif '80_' in addr:\n",
    "            labels.append(70)\n",
    "        elif '90_' in addr:\n",
    "            labels.append(70)\n",
    "    return labels\n",
    "\n",
    "labels = createLabels(addrs)\n",
    "#testLabels = createLabels(testAddrs)\n",
    "addrs = np.string_(addrs)\n",
    "#testAddrs = np.string_(testAddrs)\n",
    "\n",
    "\n",
    " \n",
    "            \n",
    "#labels = [10 if '10' in addr else 30 for addr in addrs]  # 10 = 10, 30 = 30\n",
    "\n",
    "# to shuffle data\n",
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)\n",
    "    \n",
    "# Divide the data into 80% train, 10% validation, and 10% test\n",
    "#train_addrs = addrs[0:int(0.7*len(addrs))]\n",
    "#train_labels = labels[0:int(0.7*len(labels))]\n",
    "#test_addrs = addrs[int(0.7*len(addrs)):]\n",
    "#test_labels = labels[int(0.7*len(labels)):]\n",
    "\n",
    "'''Uncomment to use separate folder for test images'''\n",
    "test_addrs = addrs[int(0.9*len(addrs)):]\n",
    "test_labels = labels[int(0.9*len(labels)):]\n",
    "\n",
    "dev_addrs = addrs[int(0.8*len(addrs)):int(0.9*len(addrs))]\n",
    "dev_labels = labels[int(0.8*len(labels)):int(0.9*len(labels))]\n",
    "\n",
    "train_addrs = addrs[0:int(0.8*len(addrs))]\n",
    "train_labels = labels[0:int(0.8*len(labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16300"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_addrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shape = (len(train_addrs), img_height, img_width, 3)\n",
    "test_shape = (len(test_addrs), img_height, img_width, 3)\n",
    "dev_shape = (len(dev_addrs), img_height, img_width, 3) # New\n",
    "\n",
    "# open a hdf5 file and create earrays\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "hdf5_file.create_dataset(\"train_imgs_resized\", train_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"test_imgs_resized\", test_shape, np.int8)\n",
    "hdf5_file.create_dataset(\"dev_imgs_resized\", dev_shape, np.int8) #new\n",
    "\n",
    "#hdf5_file.create_dataset(\"train_mean\", train_shape[1:], np.float32)\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),), np.int8)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "hdf5_file.create_dataset(\"train_addrs\", (len(train_addrs),), dtype=\"S20\")\n",
    "hdf5_file[\"train_addrs\"][...] = train_addrs\n",
    "hdf5_file.create_dataset(\"test_addrs\", (len(test_addrs),), dtype=\"S20\")\n",
    "hdf5_file[\"test_addrs\"][...] = test_addrs\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_addrs),), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels\n",
    "#New \n",
    "hdf5_file.create_dataset(\"dev_addrs\", (len(dev_addrs),), dtype=\"S20\")\n",
    "hdf5_file[\"dev_addrs\"][...] = dev_addrs\n",
    "hdf5_file.create_dataset(\"dev_labels\", (len(dev_addrs),), np.int8)\n",
    "hdf5_file[\"dev_labels\"][...] = dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a numpy array to save the mean of the images\n",
    "mean = np.zeros(train_shape[1:], np.float32)\n",
    "# loop over train addresses\n",
    "for i in range(len(train_addrs)):\n",
    "   \n",
    "    # read an image \n",
    "    addr = train_addrs[i]\n",
    "    #print(str(addr))\n",
    "    \n",
    "    # cv2 load images\n",
    "    img = cv2.imread(addr.decode('utf-8'))\n",
    "    \n",
    "    # save the image and calculate the mean so far\n",
    "    hdf5_file[\"train_imgs_resized\"][i, ...] = img[None]\n",
    "    mean += img / float(len(train_labels))\n",
    "\n",
    "# loop over test addresses\n",
    "for i in range(len(test_addrs)):\n",
    "   \n",
    "    # read an image \n",
    "    # cv2 load images\n",
    "    addr = test_addrs[i]\n",
    "    img = cv2.imread(addr.decode('utf-8'))\n",
    "    \n",
    "    # save the image\n",
    "    hdf5_file[\"test_imgs_resized\"][i, ...] = img[None]\n",
    "\n",
    "# loop over dev addresses\n",
    "for i in range(len(dev_addrs)):\n",
    "   \n",
    "    # read an image \n",
    "    # cv2 load images\n",
    "    addr = dev_addrs[i]\n",
    "    img = cv2.imread(addr.decode('utf-8'))\n",
    "    \n",
    "    # save the image\n",
    "    hdf5_file[\"dev_imgs_resized\"][i, ...] = img[None]\n",
    "# save the mean and close the hdf5 file\n",
    "#hdf5_file[\"train_mean\"][...] = mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "082bd1cb04d28c61bf8f444dd2514aaa1445b5335bf61d7f3e0a9ed0d28b3c4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
